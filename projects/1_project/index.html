<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Sketch to Reality | Victor Barberteguy </title> <meta name="author" content="Victor Barberteguy"> <meta name="description" content="This project investigates several LLM fine-tuning methods to assess the understanding and creation of art"> <meta name="keywords" content="Victor, Barberteguy, academic-website, AI, Multimodal, Video"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://victorbbt.github.io/projects/1_project/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Victor</span> Barberteguy </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Sketch to Reality</h1> <p class="post-description">This project investigates several LLM fine-tuning methods to assess the understanding and creation of art</p> </header> <article> <h1 id="sketchtoreality-enhancing-ais-understanding-and-creation-of-art">SketchToReality: Enhancing AIâ€™s Understanding and Creation of art</h1> <div> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/intro-480.webp 480w,/assets/img/intro-800.webp 800w,/assets/img/intro-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/intro.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="intro" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <p>This is the final project done for the course Advanced Computer Vision given by Vicky Kalogeiton at Ecole Polytechnique. This project aims to assess how models deal with stylistic differences between images such as realistic images ad simple sketches.</p> <p>More precisely, we finetune diffusion models on the <a href="https://faculty.cc.gatech.edu/~hays/tmp/sketchy-database.pdf" rel="external nofollow noopener" target="_blank">Sketchy Database</a> to try to incorporate the sketch style within diffusion models. To get acquainted with the database, you ca either run locally (resp. on Colab) the notebook <strong>data_visualization.ipynb</strong> (resp <strong>data_visualization.ipynb</strong>). To achieve our goal, we investigated two approaches:</p> <ul> <li> <strong>Text-in-the-middle approach:</strong> use Image Captioning Models we first generate captions with pretrained models such as <a href="https://huggingface.co/docs/transformers/model_doc/llava" rel="external nofollow noopener" target="_blank">Llava</a> and <a href="https://huggingface.co/docs/transformers/model_doc/blip-2" rel="external nofollow noopener" target="_blank">Blip2</a>.</li> <li> <strong>Direct Method:</strong> directly finetune Diffusion Models using <a href="https://dreambooth.github.io" rel="external nofollow noopener" target="_blank">DreamBooth</a> or <a href="https://textual-inversion.github.io" rel="external nofollow noopener" target="_blank">Textual Inversion</a>.</li> </ul> <h2 id="text-in-the-middle-approach">Text-in-the-middle approach</h2> <p>Although textual description of sketches can be whether to simple or clumsy (explain verbally the pose ad the different features of the sketches), we thought that is was possible to describe sketches with enough precision using Image Captioning Models. These captions are then used to generate images with <a href="https://huggingface.co/spaces/stabilityai/stable-diffusion" rel="external nofollow noopener" target="_blank">StableDiffusions</a>.</p> <p>First, we identify and try ten different prompts (we used ChatGPT to get ideas) that could help us get precise captions. We then compare the captions produced by two different models, namely <a href="https://huggingface.co/docs/transformers/model_doc/llava" rel="external nofollow noopener" target="_blank">Llava</a> and <a href="https://huggingface.co/docs/transformers/model_doc/blip-2" rel="external nofollow noopener" target="_blank">Blip2</a> qualitatively and quantitatively (length of the answers, accuracy). The different prompts and answers provided by Llava are available in the <strong>Inference_with_LLava_for_multimodal_generation.ipynb</strong>. In <strong>Inference_with_BLIP_2_(int8).ipynb</strong>, we only try the 3 best prompts found with Llava to generate captions. Then, we generate images with StableDiffusions1.5, and assess the quality of the generated images with the <strong>FrÃ©chet Inception Distance</strong>, using <a href="https://github.com/mseitzer/pytorch-fid" rel="external nofollow noopener" target="_blank">this implementation</a>.</p> <h2 id="direct-approach">Direct Approach</h2> <p>In this part, we use recent models to incorporate specific subjects in diffusion models. The goal is to convey, with few sketches, an idea of what is a sketch. The generated images can be found in <em>mosaics</em>.</p> <p>The most recent model is <a href="https://dreambooth.github.io" rel="external nofollow noopener" target="_blank">DreamBooth</a>, that consists in attaching a subject (preset in 1~5 images) to an unknown word of the Diffusion Modelâ€™s vocabulary. This methods finetunes all the weights of the model. We used DreamBooth with different sketches, whether of the same class (cat, dog) or with a sequential training with different classes. The training code and inference examples can be found in the notebooks <strong>dreambooth.ipynb</strong> and <strong>dreambooth_sequential.ipynb</strong>. We also try to finetune a diffusion model with <a href="https://textual-inversion.github.io" rel="external nofollow noopener" target="_blank">Textual Inversion</a> in <strong>textual_inversio.ipynb</strong></p> <p>Finally, we generate images for the same 100 images as in the text-in-the-middle approach in <strong>Inference_with_Dreambooth.ipynb</strong>, and assess the quality of the generation.</p> <h2 id="running-the-code">Running the code</h2> <p>Running the notebook should be seamless in any cuda environment, as all the required installations are done within the notebooks. To build the <em>train, test</em> and <em>validation</em> splits for the Sketchy database, run the codes provided in <strong>utils</strong>. To do so, you should already have downloaded in your local repository the original dataset.</p> <h3 id="so-what-is-art-">So what is art ?</h3> <p>If these questions about the nature of art and the notion of creation interest you, you can re d (in French) the book of Alban Leveau-Vallier <em>IA: lâ€™intuition Ã  lâ€™Ã©preuve des algorithmes</em>. Now, we leave you with these beautiful (real or generated ?) butterflies ðŸ¦‹</p> <div> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/butterfly-480.webp 480w,/assets/img/butterfly-800.webp 800w,/assets/img/butterfly-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/butterfly.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="butterfly" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> Â© Copyright 2025 Victor Barberteguy. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Last updated: January 14, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?70d799092f862ad98c7876aa47712e20"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>