---
layout: about
title: about
permalink: /
subtitle: 1st year PhD student in Multimodal AI.
tagline: About | Victor Barberteguy's personal page
description: personal web page containing publications, projects, ... about multimodal AI
footnote:
profile:
  align: right
  image: me_50_4.jpg
  image_circular: false # crops the image to make it circular
  more_info: >
news: true # includes a list of news items
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page
---

Hi! I am a 1st year PhD student at [Google DeepMind](https://deepmind.google) and [Imagine Group](https://imagine-lab.enpc.fr) at ENPC, working on multimodal AI agents. What drives my research is to enable machines to interpret and combine sensory data from multiple modalities (image, text, video, audio, 3D) like we humans are able to, to then enhance their reasoning and abstraction capabilities.


Before that, I graduated from Ecole Polytechnique in AI and Visual Computing with a minor in CyberPhysical Systems. Throughout my education, I had the chance to discover fascinating fields that intersect with AI like robotics ðŸ¤– at [CNRS-AIST Joint Robotics Laboratory](https://unit.aist.go.jp/jrl-22022/en/), and computational cognitive sciences ðŸ§  at [MIT CoCoSci](https://cocosci.mit.edu).
