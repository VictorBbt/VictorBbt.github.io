---
layout: about
title: about
permalink: /
subtitle: 1st year PhD student in Multomodal AI.

profile:
  align: right
  image: prof_pic.jpg
  image_circular: false # crops the image to make it circular
  more_info: >
Replace forename and lastname in the e-mail address
news: true # includes a list of news items
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page
---

Hi! I am a 1st year PhD student at [Google Deepmind](https://deepmind.google) and [Imagine Group](https://imagine-lab.enpc.fr) at ENPC. What drives my research is to enable machines to interpret and combine sensory data from multiple modalities (image, text, video, audio, 3D) like we humans are able to, to then enhance their reasoning and abstraction capabilities.
Add supervisors blabla

I graduated from Ecole Polytechnique in AI and Visual Computing with a minor in CyberPhysical Systems. Throughout my education, I had the chance to discover fascinating fields that intersect with AI like robotics ðŸ¤– at [CNRS-AIST Joint Robotics Laboratory](https://unit.aist.go.jp/jrl-22022/en/), and computational cognitive sciences ðŸ§  at [MIT CoCoSci](https://cocosci.mit.edu).
